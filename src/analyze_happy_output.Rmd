---
title: "analyze_happy_output"
author: "Ofer Isakov"
date: '2023-01-26'
output: html_document
---

```{r setup, include=FALSE}
vcf_analysis_folder<-'/media/SSD/Bioinformatics/Projects/vcf_tools_2023/'
project_dir<-vcf_analysis_folder
knitr::opts_knit$set(root.dir=project_dir)
knitr::opts_chunk$set(echo = F)
library(ProjectTemplate)
setwd(project_dir)
load.project()
```

```{r read_data}
reference_file<-'/media/SSD/Bioinformatics/Databases/hg19/hg19.fa'
regions_of_interest<-c()
#regions_of_interest<-c('xgen-exome-research-panel-v2-targets-hg19')
comparison_folder<-'./data/happy_comparisons/giab_wgs_for_quality_metrics_norm'
#comparison_folder<-'./data/happy_comparisons/exomes'
#comparison_folder<-'./data/happy_comparisons/test_chr3'
files_to_compare<-read_delim(glue('{comparison_folder}/comparison_sheet.csv'))
#join_by_cols<-c('ChromKey','POS','gt_GT_alleles')
join_by_cols<-c('CHROM','POS','REF','ALT')

comp_vcf_all<-NULL
happy_tidy_vcfs<-list()
original_tidy_vcfs<-list()
for (i in 1:nrow(files_to_compare)){
  original_vcf_name<-files_to_compare%>%slice(i)%>%pull(original_vcf)
  message(glue('parsing {original_vcf_name}..'))
  happy_vcf_name<-files_to_compare%>%slice(i)%>%pull(happy_vcf)
  original_vcf<-read.vcfR(original_vcf_name)
  if (length(regions_of_interest)>0){
    happy_vcf_in_roi<-filter_happy_vcf_by_region(happy_vcf_name,regions_of_interest)
  }else{
    happy_vcf_in_roi<-happy_vcf_name
  }
  happy_vcf<-read.vcfR(happy_vcf_in_roi)
  original_vcf_df<-vcf_to_tidy(original_vcf,happy_individual = NA)
  original_tidy_vcfs[[original_vcf_name]]<-original_vcf_df
  
  happy_vcf_df<-vcf_to_tidy(happy_vcf,happy_individual = 'QUERY')
  # remove nocall from happy vcf (dont care about false negatives)
  happy_vcf_df<-happy_vcf_df%>%filter(gt_BLT!='nocall')
  happy_tidy_vcfs[[happy_vcf_name]]<-happy_vcf_df
  
  comp_vcf<-happy_vcf_df%>%select(all_of(join_by_cols),gt_BD,gt_BVT,gt_BLT)%>%
    left_join(original_vcf_df,by=join_by_cols)
  
  comp_vcf_all<-comp_vcf_all%>%bind_rows(comp_vcf)
}

comp_vcf_all%>%count(gt_BD)
# f_original<-original_vcf_df%>%separate_rows(ALT,sep=',')
# f_happy<-happy_vcf_df%>%separate_rows(ALT,sep=',')
# comp_after_sep<-f_happy%>%select(all_of(join_by_cols),gt_BD,gt_BVT,gt_BLT)%>%
#     left_join(f_original,by=join_by_cols)
# # 
# z<-happy_vcf_df%>%select(all_of(join_by_cols),gt_BD,gt_BLT,gt_BVT)%>%
#   filter(gt_BLT!='nocall')%>%
#   left_join(original_vcf_df,by=join_by_cols)
# 
# z%>%filter(is.na(gt_GT))%>%head()

library(arrow)
write_feather(comp_vcf_all,glue('{comparison_folder}/all_vcfs_as_tidy.feather'))

```

```{r plot_metrics_vs_calls}
features_to_plot<-c('QUAL','MQ','gt_DP','gt_GQ','gt_AF')
# Plot metrics by SNP/INDEL
comp_vcf_all%>%
  mutate(gt_AF=as.numeric(gt_AF))%>%
  slice_sample(n=100000)%>%
  filter(gt_BD!='UNK')%>%
  select(gt_BVT,gt_BD,gt_BLT,features_to_plot)%>%
  pivot_longer(-c(gt_BD,gt_BVT,gt_BLT))%>%
  ggplot(aes(x=value,fill=gt_BD))+
  geom_density(alpha=0.5)+
  facet_wrap(name~gt_BVT,scales='free')+
  theme_minimal()+
  labs(fill='True / False Positive')+
  ggsci::scale_fill_nejm()+
  theme(legend.position = 'top')

# Plot metrics by het/homalt
comp_vcf_all%>%
  slice_sample(n=100000)%>%
  filter(gt_BD!='UNK')%>%filter(gt_BLT%in%c('het','homalt'))%>%
  select(gt_BVT,gt_BD,gt_BLT,features_to_plot)%>%
  pivot_longer(-c(gt_BD,gt_BVT,gt_BLT))%>%
  ggplot(aes(x=value,fill=gt_BD))+
  geom_density(alpha=0.5)+
  facet_wrap(name~gt_BLT,scales='free')+
  theme_minimal()+
  labs(fill='True / False Positive')+
  ggsci::scale_fill_nejm()+
  theme(legend.position = 'top')


```

https://rpubs.com/StatsGary/tidymodels_from_scratch

```{r ml_definitions}
library(tidymodels)
############################################################################################################
# model defintions
############################################################################################################
#features<-c('QUAL','MQ','gt_AF','gt_BVT','gt_DP','gt_GQ','QD','MQRankSum','ReadPosRankSum')
set.seed(123)
features<-c('gt_BVT','QUAL','MQ','gt_DP','gt_GQ','gt_AF')
strata<-'gt_BD'
included_BVT<-c('SNP') # either SNP or INDEL or both
form<-as.formula(glue('{strata} ~ {paste0(features,collapse="+")}'))
# optional grids
manual_grid<-expand.grid(cost_complexity=c(0.00001,0.0001,0.001),tree_depth=c(4,5,6))
regular_grid <- grid_regular(dials::cost_complexity(),
                               dials::tree_depth(),
                               levels = 3)
sample_size<-500000
############################################################################################################
```

```{r prep_data_for_ml}
# Prepare the data for ML
ml_data<-comp_vcf_all%>%
  filter(gt_BD%in%c('TP','FP'))%>%
  filter(gt_BVT%in%included_BVT)%>%
  slice_sample(n=sample_size)%>%
  mutate(gt_BD=factor(gt_BD),
         gt_AF=as.numeric(gt_AF),
         gt_DP=as.numeric(gt_DP),
         gt_GQ=as.numeric(gt_GQ),
         gt_QD=as.numeric(QD))

ml_data%>%count(gt_BD,gt_BVT)
ml_data%>%group_by(gt_BVT,gt_BD)%>%
  skimr::skim_without_charts(all_of(features))

ml_data<-ml_data[complete.cases(ml_data%>%select(all_of(features))),]
```

```{r train_model}
# Partition into training and hold out test / validation sample
train_test<-split_train_test(ml_data,strata=strata)
train_data <- train_test[['train']]
test_data <- train_test[['test']]
# Set cross validation data
vfold <- vfold_cv(train_data, v=5)

# set up the recipe
rec <- 
  recipe(form, data=train_data)#%>%
  #step_smote(gt_BD, over_ratio = 0.3)
# set up the tuning process
decision_tree_tuning_setup <- setup_decision_tree_tuning()
# set up the workflow
decision_tree_wf <- setup_decision_tree_workflow(recipe = rec,
                                                 tuning_setup = decision_tree_tuning_setup)

# Evaluate model performance on cross validation using the different tuning parameters
tuning_res<-train_model_on_tuning_grid(workflow_with_tune = decision_tree_wf,
                                       vfold = vfold,
                                       selected_grid = manual_grid)

# collected metrics
collected_mets <- tune::collect_metrics(tuning_res)
print(collected_mets)

best_tree <- tuning_res %>% 
  tune::select_best("roc_auc")

final_decision_tree_wf <- 
  decision_tree_wf %>% 
  finalize_workflow(best_tree) #Finalise workflow passes in our best tree

print(final_decision_tree_wf)

final_decision_tree <- 
  final_decision_tree_wf %>% 
  fit(data = train_data)

print(final_decision_tree)
```

```{r plot_tree}
tree_fit <- final_decision_tree %>% 
  extract_fit_parsnip()
library(rpart.plot)
rpart.plot(tree_fit$fit,
           type=1,
           extra=105)
```

```{r evaluate}
# Predict on holdout set
class_pred <- predict(tree_fit, test_data) #Get the class label predictions
prob_pred <- predict(tree_fit, test_data, type="prob") #Get the probability predictions
predictions <- data.frame(class_pred, prob_pred) %>% 
  setNames(c("pred_class", "pred_FP", "pred_TP")) #Combined into tibble and rename


get_logical_vector <- function(df, condition) {
  condition_to_parse<-paste0(paste("df$",condition,sep = ''),collapse='&')
  print(condition_to_parse)
  logical_vector <- eval(parse(text = condition_to_parse))
  return(logical_vector)
}

test_data_fixed<-test_data[complete.cases(test_data%>%select(QUAL,DP,MQ,gt_AF,gt_GQ)),]

bin_preds<-function(input_table,conditions,col_name='bin_pred',default='intermediate'){
  input_table[,col_name]<-default
  for (i in 1:length(conditions)){
    condition_name<-names(conditions[i])
    condition=conditions[[i]]
    matching_rows<-get_logical_vector(input_table, condition)
    input_table[matching_rows,col_name]<-condition_name
  }
  return(input_table)
}

#tree_conditions<-list(high=c('QUAL>=20','MQ>50','DP>10'),low=c('QUAL<11','DP<10'))
tree_conditions<-list(high=c('gt_GQ>15'),low=c('gt_GQ<6'))
test_data_fixed<-bin_preds(test_data_fixed,col_name='tree_based_preds',tree_conditions)

count_data_tree<-test_data_fixed%>%count(tree_based_preds,gt_BD)
count_data_tree%>%left_join(count_data_tree%>%group_by(tree_based_preds)%>%summarize(total=sum(n)))%>%
  mutate(rate=n/total)

base_conditions<-list(high=c('QUAL>=20'),low=c('QUAL<10'))
test_data_fixed<-bin_preds(test_data_fixed,col_name='base_preds',base_conditions)

count_data_base<-test_data_fixed%>%count(base_preds,gt_BD)
count_data_base%>%left_join(count_data_base%>%group_by(base_preds)%>%summarize(total=sum(n)))%>%
  mutate(rate=n/total)

test_predictions <- test_data %>% 
  bind_cols(predictions)
library(caret)
cm <- caret::confusionMatrix(test_predictions$gt_BD,
                       test_predictions$pred_class,
                       positive='TP')

print(cm)
```

